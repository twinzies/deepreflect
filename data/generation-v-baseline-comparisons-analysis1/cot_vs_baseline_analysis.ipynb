{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3b5caa",
   "metadata": {},
   "source": [
    "# CoT vs Baseline Analysis for AITAH Responses\n",
    "This notebook compares responses produced by the same language models for the same `post_id` under two conditions: **baseline** and **chain-of-thought (CoT)** prompting. It performs paired, per-model analyses of stylistic, pragmatic, and readability features; runs significance tests with multiple-comparisons correction; extracts representative excerpt pairs; and visualizes differences via paired plots and word clouds.\n",
    "\n",
    "**Inputs**:\n",
    "- `/mnt/data/AITAH_all_llm_responses.csv`\n",
    "- `/mnt/data/AITAH_cot_responses_consolidated_100.csv`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d433e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 6)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, re, math, json\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_AVAILABLE = True\n",
    "except Exception:\n",
    "    SCIPY_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    SKLEARN_AVAILABLE = True\n",
    "except Exception:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except Exception:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "\n",
    "BASE_PATH = \"AITAH_all_llm_responses.csv\"\n",
    "COT_PATH  = \"AITAH_cot_responses_consolidated_100.csv\"\n",
    "OUT_DIR = \"analysis_outputs/\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "df_base = pd.read_csv(BASE_PATH)\n",
    "df_cot  = pd.read_csv(COT_PATH)\n",
    "MODEL_COLS = [c for c in df_base.columns if c.endswith(\"_response\")]\n",
    "ID_COL = \"post_id\"\n",
    "\n",
    "def melt_long(df, condition_label):\n",
    "    parts = []\n",
    "    for mcol in MODEL_COLS:\n",
    "        model_name = mcol.replace(\"_response\", \"\")\n",
    "        part = df[[ID_COL, mcol]].copy()\n",
    "        part.columns = [ID_COL, \"text\"]\n",
    "        part[\"model\"] = model_name\n",
    "        part[\"condition\"] = condition_label\n",
    "        parts.append(part)\n",
    "    return pd.concat(parts, ignore_index=True)\n",
    "\n",
    "long_base = melt_long(df_base, \"baseline\")\n",
    "long_cot  = melt_long(df_cot, \"cot\")\n",
    "paired = pd.merge(long_base, long_cot, on=[ID_COL, \"model\"], suffixes=(\"_base\", \"_cot\"))\n",
    "paired.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee4ea44",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9f91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "n_chars_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_words_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_sents_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_words_per_sent_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "qmarks_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "emarks_base",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epistemic_modal_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deontic_modal_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_person_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "second_person_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "apology_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "empathy_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "agreement_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deference_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pos_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "neg_rate_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease_base",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_chars_cot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_words_cot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_sents_cot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "avg_words_per_sent_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ttr_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "qmarks_cot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "emarks_cot",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "epistemic_modal_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deontic_modal_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "first_person_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "second_person_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "apology_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "empathy_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "agreement_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "deference_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pos_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "neg_rate_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease_cot",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_n_chars",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "delta_n_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "delta_n_sents",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "delta_avg_words_per_sent",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_ttr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_qmarks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "delta_emarks",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "delta_hedge_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_epistemic_modal_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_deontic_modal_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_first_person_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_second_person_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_apology_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_empathy_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_agreement_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_deference_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_pos_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_neg_rate",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "delta_flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "dadf244d-5ec0-47a1-855d-edfcc0203443",
       "rows": [
        [
         "0",
         "z095pe",
         "gpt4o",
         "835",
         "144",
         "7",
         "20.571428571428573",
         "0.6736111111111112",
         "0",
         "0",
         "15.277777777777779",
         "4.861111111111112",
         "0.0",
         "0.6944444444444444",
         "5.555555555555555",
         "0.0",
         "2.083333333333333",
         "0.6944444444444444",
         "5.555555555555555",
         "0.6944444444444444",
         "0.0",
         "63.16750000000002",
         "1004",
         "166",
         "7",
         "23.714285714285715",
         "0.6566265060240963",
         "0",
         "0",
         "10.843373493975903",
         "3.614457831325301",
         "0.0",
         "0.0",
         "6.626506024096386",
         "0.0",
         "2.4096385542168677",
         "0.6024096385542169",
         "3.614457831325301",
         "0.6024096385542169",
         "0.0",
         "47.71078313253014",
         "169",
         "22",
         "0",
         "3.1428571428571423",
         "-0.016984605087014826",
         "0",
         "0",
         "-4.434404283801875",
         "-1.2466532797858108",
         "0.0",
         "-0.6944444444444444",
         "1.0709504685408309",
         "0.0",
         "0.32630522088353464",
         "-0.0920348058902275",
         "-1.9410977242302545",
         "-0.0920348058902275",
         "0.0",
         "-15.45671686746988"
        ],
        [
         "1",
         "zejhz0",
         "gpt4o",
         "944",
         "152",
         "11",
         "13.818181818181818",
         "0.7105263157894737",
         "1",
         "1",
         "12.5",
         "2.631578947368421",
         "0.0",
         "0.6578947368421052",
         "3.9473684210526314",
         "0.0",
         "0.6578947368421052",
         "1.9736842105263157",
         "7.236842105263158",
         "1.3157894736842104",
         "0.0",
         "62.57007177033495",
         "836",
         "136",
         "8",
         "17.0",
         "0.7205882352941176",
         "0",
         "0",
         "13.970588235294118",
         "2.2058823529411766",
         "0.0",
         "0.0",
         "6.61764705882353",
         "0.0",
         "3.6764705882352944",
         "1.4705882352941175",
         "6.61764705882353",
         "0.0",
         "0.0",
         "55.837352941176505",
         "-108",
         "-16",
         "-3",
         "3.1818181818181817",
         "0.010061919504643968",
         "-1",
         "-1",
         "1.4705882352941178",
         "-0.42569659442724417",
         "0.0",
         "-0.6578947368421052",
         "2.6702786377708985",
         "0.0",
         "3.018575851393189",
         "-0.5030959752321982",
         "-0.6191950464396285",
         "-1.3157894736842104",
         "0.0",
         "-6.732718829158443"
        ],
        [
         "2",
         "zj9m45",
         "gpt4o",
         "979",
         "176",
         "9",
         "19.555555555555557",
         "0.6363636363636364",
         "0",
         "0",
         "10.795454545454545",
         "1.1363636363636365",
         "0.0",
         "0.5681818181818182",
         "7.386363636363637",
         "0.0",
         "0.5681818181818182",
         "1.1363636363636365",
         "5.113636363636364",
         "0.5681818181818182",
         "0.0",
         "62.4895202020202",
         "1081",
         "176",
         "8",
         "22.0",
         "0.6477272727272727",
         "0",
         "0",
         "9.659090909090908",
         "1.1363636363636365",
         "0.0",
         "0.0",
         "7.386363636363637",
         "0.0",
         "0.0",
         "0.5681818181818182",
         "4.545454545454546",
         "0.0",
         "0.0",
         "43.665227272727265",
         "102",
         "0",
         "-1",
         "2.444444444444443",
         "0.011363636363636354",
         "0",
         "0",
         "-1.1363636363636367",
         "0.0",
         "0.0",
         "-0.5681818181818182",
         "0.0",
         "0.0",
         "-0.5681818181818182",
         "-0.5681818181818182",
         "-0.5681818181818183",
         "-0.5681818181818182",
         "0.0",
         "-18.824292929292938"
        ],
        [
         "3",
         "y1noss",
         "gpt4o",
         "1020",
         "164",
         "10",
         "16.4",
         "0.6890243902439024",
         "0",
         "1",
         "9.146341463414634",
         "1.8292682926829267",
         "0.0",
         "0.6097560975609756",
         "4.878048780487805",
         "0.0",
         "1.2195121951219512",
         "3.048780487804878",
         "3.048780487804878",
         "0.6097560975609756",
         "0.0",
         "51.94021951219517",
         "1095",
         "183",
         "8",
         "22.875",
         "0.5956284153005464",
         "0",
         "0",
         "10.382513661202186",
         "2.73224043715847",
         "0.0",
         "0.0",
         "9.289617486338798",
         "0.0",
         "1.639344262295082",
         "0.0",
         "4.918032786885246",
         "1.092896174863388",
         "0.546448087431694",
         "46.77753073770495",
         "75",
         "19",
         "-2",
         "6.475000000000001",
         "-0.09339597494335594",
         "0",
         "-1",
         "1.2361721977875515",
         "0.9029721444755432",
         "0.0",
         "-0.6097560975609756",
         "4.411568705850994",
         "0.0",
         "0.4198320671731308",
         "-3.048780487804878",
         "1.869252299080368",
         "0.4831400773024125",
         "0.546448087431694",
         "-5.162688774490221"
        ],
        [
         "4",
         "ywefto",
         "gpt4o",
         "860",
         "148",
         "9",
         "16.444444444444443",
         "0.7094594594594594",
         "0",
         "1",
         "12.162162162162163",
         "2.7027027027027026",
         "0.0",
         "1.3513513513513513",
         "6.081081081081082",
         "0.0",
         "2.027027027027027",
         "3.3783783783783785",
         "8.108108108108109",
         "2.027027027027027",
         "0.0",
         "67.24524024024028",
         "1080",
         "177",
         "10",
         "17.7",
         "0.6440677966101694",
         "0",
         "0",
         "11.864406779661017",
         "3.389830508474576",
         "0.0",
         "0.0",
         "6.779661016949152",
         "0.0",
         "3.954802259887006",
         "1.694915254237288",
         "5.084745762711865",
         "1.1299435028248588",
         "0.0",
         "55.51695762711867",
         "220",
         "29",
         "1",
         "1.2555555555555564",
         "-0.06539166284928999",
         "0",
         "-1",
         "-0.29775538250114586",
         "0.6871278057718735",
         "0.0",
         "-1.3513513513513513",
         "0.6985799358680707",
         "0.0",
         "1.9277752328599789",
         "-1.6834631241410905",
         "-3.0233623453962437",
         "-0.8970835242021684",
         "0.0",
         "-11.728282613121607"
        ]
       ],
       "shape": {
        "columns": 59,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>model</th>\n",
       "      <th>n_chars_base</th>\n",
       "      <th>n_words_base</th>\n",
       "      <th>n_sents_base</th>\n",
       "      <th>avg_words_per_sent_base</th>\n",
       "      <th>ttr_base</th>\n",
       "      <th>qmarks_base</th>\n",
       "      <th>emarks_base</th>\n",
       "      <th>hedge_rate_base</th>\n",
       "      <th>...</th>\n",
       "      <th>delta_deontic_modal_rate</th>\n",
       "      <th>delta_first_person_rate</th>\n",
       "      <th>delta_second_person_rate</th>\n",
       "      <th>delta_apology_rate</th>\n",
       "      <th>delta_empathy_rate</th>\n",
       "      <th>delta_agreement_rate</th>\n",
       "      <th>delta_deference_rate</th>\n",
       "      <th>delta_pos_rate</th>\n",
       "      <th>delta_neg_rate</th>\n",
       "      <th>delta_flesch_reading_ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>z095pe</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>835</td>\n",
       "      <td>144</td>\n",
       "      <td>7</td>\n",
       "      <td>20.571429</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.277778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.694444</td>\n",
       "      <td>1.070950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326305</td>\n",
       "      <td>-0.092035</td>\n",
       "      <td>-1.941098</td>\n",
       "      <td>-0.092035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.456717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zejhz0</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>944</td>\n",
       "      <td>152</td>\n",
       "      <td>11</td>\n",
       "      <td>13.818182</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.657895</td>\n",
       "      <td>2.670279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.018576</td>\n",
       "      <td>-0.503096</td>\n",
       "      <td>-0.619195</td>\n",
       "      <td>-1.315789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.732719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zj9m45</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>979</td>\n",
       "      <td>176</td>\n",
       "      <td>9</td>\n",
       "      <td>19.555556</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.795455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.568182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.568182</td>\n",
       "      <td>-0.568182</td>\n",
       "      <td>-0.568182</td>\n",
       "      <td>-0.568182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-18.824293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y1noss</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>1020</td>\n",
       "      <td>164</td>\n",
       "      <td>10</td>\n",
       "      <td>16.400000</td>\n",
       "      <td>0.689024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.146341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.609756</td>\n",
       "      <td>4.411569</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.419832</td>\n",
       "      <td>-3.048780</td>\n",
       "      <td>1.869252</td>\n",
       "      <td>0.483140</td>\n",
       "      <td>0.546448</td>\n",
       "      <td>-5.162689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ywefto</td>\n",
       "      <td>gpt4o</td>\n",
       "      <td>860</td>\n",
       "      <td>148</td>\n",
       "      <td>9</td>\n",
       "      <td>16.444444</td>\n",
       "      <td>0.709459</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12.162162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.351351</td>\n",
       "      <td>0.698580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927775</td>\n",
       "      <td>-1.683463</td>\n",
       "      <td>-3.023362</td>\n",
       "      <td>-0.897084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.728283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id  model  n_chars_base  n_words_base  n_sents_base  \\\n",
       "0  z095pe  gpt4o           835           144             7   \n",
       "1  zejhz0  gpt4o           944           152            11   \n",
       "2  zj9m45  gpt4o           979           176             9   \n",
       "3  y1noss  gpt4o          1020           164            10   \n",
       "4  ywefto  gpt4o           860           148             9   \n",
       "\n",
       "   avg_words_per_sent_base  ttr_base  qmarks_base  emarks_base  \\\n",
       "0                20.571429  0.673611            0            0   \n",
       "1                13.818182  0.710526            1            1   \n",
       "2                19.555556  0.636364            0            0   \n",
       "3                16.400000  0.689024            0            1   \n",
       "4                16.444444  0.709459            0            1   \n",
       "\n",
       "   hedge_rate_base  ...  delta_deontic_modal_rate  delta_first_person_rate  \\\n",
       "0        15.277778  ...                       0.0                -0.694444   \n",
       "1        12.500000  ...                       0.0                -0.657895   \n",
       "2        10.795455  ...                       0.0                -0.568182   \n",
       "3         9.146341  ...                       0.0                -0.609756   \n",
       "4        12.162162  ...                       0.0                -1.351351   \n",
       "\n",
       "   delta_second_person_rate  delta_apology_rate  delta_empathy_rate  \\\n",
       "0                  1.070950                 0.0            0.326305   \n",
       "1                  2.670279                 0.0            3.018576   \n",
       "2                  0.000000                 0.0           -0.568182   \n",
       "3                  4.411569                 0.0            0.419832   \n",
       "4                  0.698580                 0.0            1.927775   \n",
       "\n",
       "   delta_agreement_rate  delta_deference_rate  delta_pos_rate  delta_neg_rate  \\\n",
       "0             -0.092035             -1.941098       -0.092035        0.000000   \n",
       "1             -0.503096             -0.619195       -1.315789        0.000000   \n",
       "2             -0.568182             -0.568182       -0.568182        0.000000   \n",
       "3             -3.048780              1.869252        0.483140        0.546448   \n",
       "4             -1.683463             -3.023362       -0.897084        0.000000   \n",
       "\n",
       "   delta_flesch_reading_ease  \n",
       "0                 -15.456717  \n",
       "1                  -6.732719  \n",
       "2                 -18.824293  \n",
       "3                  -5.162689  \n",
       "4                 -11.728283  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "WORD_RE = re.compile(r\"[A-Za-z']+\")\n",
    "\n",
    "def tokenize(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = \"\" if pd.isna(text) else str(text)\n",
    "    return WORD_RE.findall(text.lower())\n",
    "\n",
    "def sentence_split(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    return [s.strip() for s in re.split(r\"[.!?]+\", text) if s.strip()]\n",
    "\n",
    "def count_syllables_en(word):\n",
    "    word = word.lower()\n",
    "    if not word:\n",
    "        return 0\n",
    "    vowels = \"aeiouy\"\n",
    "    count = 0\n",
    "    prev_vowel = False\n",
    "    for ch in word:\n",
    "        is_vowel = ch in vowels\n",
    "        if is_vowel and not prev_vowel:\n",
    "            count += 1\n",
    "        prev_vowel = is_vowel\n",
    "    if word.endswith(\"e\") and count > 1:\n",
    "        count -= 1\n",
    "    return max(1, count)\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "    toks = tokenize(text)\n",
    "    sents = sentence_split(text)\n",
    "    n_words = len(toks)\n",
    "    n_sents = max(1, len(sents))\n",
    "    if n_words == 0:\n",
    "        return np.nan\n",
    "    syllables = sum(count_syllables_en(w) for w in toks)\n",
    "    return 206.835 - 1.015 * (n_words / n_sents) - 84.6 * (syllables / n_words)\n",
    "\n",
    "HEDGES = set(\"\"\"maybe perhaps seemingly apparently arguably roughly kind of sort of somewhat relatively likely unlikely possibly probably generally typically usually tends to it seems it appears i think i feel i guess could might may would suggest consider\"\"\".split())\n",
    "MODALS_EPIST = set(\"might may could perhaps possibly seems appear\".split())\n",
    "MODALS_DEON  = set(\"should must need shall ought\".split())\n",
    "FIRST_PERSON = set(\"i me my mine myself\".split())\n",
    "SECOND_PERSON = set(\"you your yours yourself yourselves\".split())\n",
    "APOLOGY = set(\"sorry apologize apologies regret\".split())\n",
    "EMPATHY = set(\"\"\"understand understood understandable feel felt feeling empathize empathy validate validation valid heard hear listening listen support supportive care cared caring appreciate appreciated appreciation compassion compassionate\"\"\".split())\n",
    "PHRASES_AGREE = [\"you're right\", \"youre right\", \"i agree\", \"great point\", \"good point\", \"exactly right\"]\n",
    "DEFERENCE = set(\"\"\"please kindly would you could you if you want if you'd like if you’d like maybe you could perhaps you could consider\"\"\".split())\n",
    "POS_LEX = set(\"\"\"good great excellent helpful kind positive supportive considerate fair honest respectful\"\"\".split())\n",
    "NEG_LEX = set(\"\"\"bad wrong harmful rude cruel negative unfair dishonest disrespectful toxic\"\"\".split())\n",
    "\n",
    "def count_lexicon(tokens, lexicon):\n",
    "    return sum(1 for t in tokens if t in lexicon)\n",
    "\n",
    "def count_phrases(text, phrases):\n",
    "    t = text.lower()\n",
    "    return sum(t.count(p) for p in phrases)\n",
    "\n",
    "def extract_features(text):\n",
    "    toks = tokenize(text)\n",
    "    sents = sentence_split(text)\n",
    "    n_words = len(toks)\n",
    "    n_chars = len(text) if isinstance(text, str) else 0\n",
    "    n_sents = len(sents)\n",
    "    unique_words = len(set(toks))\n",
    "    ttr = (unique_words / n_words) if n_words else np.nan\n",
    "    qmarks = text.count(\"?\") if isinstance(text, str) else 0\n",
    "    emarks = text.count(\"!\") if isinstance(text, str) else 0\n",
    "    def rate(count): \n",
    "        return (count / n_words * 100.0) if n_words else 0.0\n",
    "    hedge_count = count_lexicon(toks, HEDGES)\n",
    "    deon_count  = count_lexicon(toks, MODALS_DEON)\n",
    "    epistemic_count = count_lexicon(toks, MODALS_EPIST)\n",
    "    fp_count    = count_lexicon(toks, FIRST_PERSON)\n",
    "    sp_count    = count_lexicon(toks, SECOND_PERSON)\n",
    "    apo_count   = count_lexicon(toks, APOLOGY)\n",
    "    emp_count   = count_lexicon(toks, EMPATHY)\n",
    "    agree_uni   = count_lexicon(toks, set([w for p in PHRASES_AGREE for w in p.split()]))\n",
    "    agree_ph    = count_phrases(text, PHRASES_AGREE)\n",
    "    defer_count = count_lexicon(toks, DEFERENCE)\n",
    "    pos_count   = count_lexicon(toks, POS_LEX)\n",
    "    neg_count   = count_lexicon(toks, NEG_LEX)\n",
    "    fre = flesch_reading_ease(text)\n",
    "    return {\n",
    "        \"n_chars\": n_chars,\n",
    "        \"n_words\": n_words,\n",
    "        \"n_sents\": n_sents,\n",
    "        \"avg_words_per_sent\": (n_words / n_sents) if n_sents else np.nan,\n",
    "        \"ttr\": ttr,\n",
    "        \"qmarks\": qmarks,\n",
    "        \"emarks\": emarks,\n",
    "        \"hedge_rate\": rate(hedge_count),\n",
    "        \"epistemic_modal_rate\": rate(epistemic_count),\n",
    "        \"deontic_modal_rate\": rate(deon_count),\n",
    "        \"first_person_rate\": rate(fp_count),\n",
    "        \"second_person_rate\": rate(sp_count),\n",
    "        \"apology_rate\": rate(apo_count),\n",
    "        \"empathy_rate\": rate(emp_count),\n",
    "        \"agreement_rate\": rate(agree_uni) + rate(agree_ph*2),\n",
    "        \"deference_rate\": rate(defer_count),\n",
    "        \"pos_rate\": rate(pos_count),\n",
    "        \"neg_rate\": rate(neg_count),\n",
    "        \"flesch_reading_ease\": fre,\n",
    "    }\n",
    "\n",
    "feat_rows = []\n",
    "for _, row in paired.iterrows():\n",
    "    f_base = extract_features(row[\"text_base\"])\n",
    "    f_cot  = extract_features(row[\"text_cot\"])\n",
    "    f_base = {f\"{k}_base\": v for k, v in f_base.items()}\n",
    "    f_cot  = {f\"{k}_cot\": v for k, v in f_cot.items()}\n",
    "    feat_rows.append({\n",
    "        \"post_id\": row[\"post_id\"],\n",
    "        \"model\": row[\"model\"],\n",
    "        **f_base, **f_cot\n",
    "    })\n",
    "\n",
    "feat_df = pd.DataFrame(feat_rows)\n",
    "for k in [c.replace(\"_base\",\"\") for c in feat_df.columns if c.endswith(\"_base\")]:\n",
    "    feat_df[f\"delta_{k}\"] = feat_df[f\"{k}_cot\"] - feat_df[f\"{k}_base\"]\n",
    "feat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb3a76e",
   "metadata": {},
   "source": [
    "## Significance Testing (paired, per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e2e6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "p_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "q_value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "significant_q<0.05",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ec45bcc9-8f0f-4823-a498-2b4f430dc2e2",
       "rows": [
        [
         "2",
         "claude",
         "n_sents",
         "1.672337651627534e-13",
         "3.1774415380923146e-12",
         "True"
        ],
        [
         "18",
         "claude",
         "flesch_reading_ease",
         "1.8443819517688173e-12",
         "1.7521628541803764e-11",
         "True"
        ],
        [
         "13",
         "claude",
         "empathy_rate",
         "7.860319584902938e-11",
         "4.978202403771861e-10",
         "True"
        ],
        [
         "3",
         "claude",
         "avg_words_per_sent",
         "2.788635221590487e-10",
         "1.3246017302554814e-09",
         "True"
        ],
        [
         "8",
         "claude",
         "epistemic_modal_rate",
         "1.5715231716471523e-08",
         "5.97178805225918e-08",
         "True"
        ],
        [
         "10",
         "claude",
         "first_person_rate",
         "9.308415118145607e-05",
         "0.0002947664787412776",
         "True"
        ],
        [
         "7",
         "claude",
         "hedge_rate",
         "0.00023848828630474914",
         "0.000647325348541462",
         "True"
        ],
        [
         "9",
         "claude",
         "deontic_modal_rate",
         "0.0029317488918706486",
         "0.006962903618192791",
         "True"
        ],
        [
         "12",
         "claude",
         "apology_rate",
         "0.005482709746625545",
         "0.011574609465098373",
         "True"
        ],
        [
         "5",
         "claude",
         "qmarks",
         "0.021407628344447448",
         "0.04067449385445015",
         "True"
        ],
        [
         "1",
         "claude",
         "n_words",
         "0.05967094030819402",
         "0.09447898882130719",
         "False"
        ],
        [
         "6",
         "claude",
         "emarks",
         "0.05839774428202227",
         "0.09447898882130719",
         "False"
        ],
        [
         "14",
         "claude",
         "agreement_rate",
         "0.07010837187595655",
         "0.10246608197255187",
         "False"
        ],
        [
         "0",
         "claude",
         "n_chars",
         "0.1659251732855107",
         "0.22518416374462166",
         "False"
        ],
        [
         "16",
         "claude",
         "pos_rate",
         "0.31436469602883543",
         "0.3981952816365249",
         "False"
        ],
        [
         "15",
         "claude",
         "deference_rate",
         "0.4761117693274859",
         "0.5653827260763895",
         "False"
        ],
        [
         "4",
         "claude",
         "ttr",
         "0.5129822451879467",
         "0.5733330975629992",
         "False"
        ],
        [
         "11",
         "claude",
         "second_person_rate",
         "0.727881929034021",
         "0.7683198139803555",
         "False"
        ],
        [
         "17",
         "claude",
         "neg_rate",
         "0.8486964579199469",
         "0.8486964579199467",
         "False"
        ],
        [
         "37",
         "gpt4o",
         "flesch_reading_ease",
         "1.3573675327344952e-27",
         "2.5789983121955407e-26",
         "True"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>p_value</th>\n",
       "      <th>q_value</th>\n",
       "      <th>significant_q&lt;0.05</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claude</td>\n",
       "      <td>n_sents</td>\n",
       "      <td>1.672338e-13</td>\n",
       "      <td>3.177442e-12</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>claude</td>\n",
       "      <td>flesch_reading_ease</td>\n",
       "      <td>1.844382e-12</td>\n",
       "      <td>1.752163e-11</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>claude</td>\n",
       "      <td>empathy_rate</td>\n",
       "      <td>7.860320e-11</td>\n",
       "      <td>4.978202e-10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claude</td>\n",
       "      <td>avg_words_per_sent</td>\n",
       "      <td>2.788635e-10</td>\n",
       "      <td>1.324602e-09</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claude</td>\n",
       "      <td>epistemic_modal_rate</td>\n",
       "      <td>1.571523e-08</td>\n",
       "      <td>5.971788e-08</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>claude</td>\n",
       "      <td>first_person_rate</td>\n",
       "      <td>9.308415e-05</td>\n",
       "      <td>2.947665e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claude</td>\n",
       "      <td>hedge_rate</td>\n",
       "      <td>2.384883e-04</td>\n",
       "      <td>6.473253e-04</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claude</td>\n",
       "      <td>deontic_modal_rate</td>\n",
       "      <td>2.931749e-03</td>\n",
       "      <td>6.962904e-03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>claude</td>\n",
       "      <td>apology_rate</td>\n",
       "      <td>5.482710e-03</td>\n",
       "      <td>1.157461e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claude</td>\n",
       "      <td>qmarks</td>\n",
       "      <td>2.140763e-02</td>\n",
       "      <td>4.067449e-02</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claude</td>\n",
       "      <td>n_words</td>\n",
       "      <td>5.967094e-02</td>\n",
       "      <td>9.447899e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claude</td>\n",
       "      <td>emarks</td>\n",
       "      <td>5.839774e-02</td>\n",
       "      <td>9.447899e-02</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>claude</td>\n",
       "      <td>agreement_rate</td>\n",
       "      <td>7.010837e-02</td>\n",
       "      <td>1.024661e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claude</td>\n",
       "      <td>n_chars</td>\n",
       "      <td>1.659252e-01</td>\n",
       "      <td>2.251842e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>claude</td>\n",
       "      <td>pos_rate</td>\n",
       "      <td>3.143647e-01</td>\n",
       "      <td>3.981953e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>claude</td>\n",
       "      <td>deference_rate</td>\n",
       "      <td>4.761118e-01</td>\n",
       "      <td>5.653827e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claude</td>\n",
       "      <td>ttr</td>\n",
       "      <td>5.129822e-01</td>\n",
       "      <td>5.733331e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>claude</td>\n",
       "      <td>second_person_rate</td>\n",
       "      <td>7.278819e-01</td>\n",
       "      <td>7.683198e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>claude</td>\n",
       "      <td>neg_rate</td>\n",
       "      <td>8.486965e-01</td>\n",
       "      <td>8.486965e-01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>flesch_reading_ease</td>\n",
       "      <td>1.357368e-27</td>\n",
       "      <td>2.578998e-26</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                metric       p_value       q_value  \\\n",
       "2   claude               n_sents  1.672338e-13  3.177442e-12   \n",
       "18  claude   flesch_reading_ease  1.844382e-12  1.752163e-11   \n",
       "13  claude          empathy_rate  7.860320e-11  4.978202e-10   \n",
       "3   claude    avg_words_per_sent  2.788635e-10  1.324602e-09   \n",
       "8   claude  epistemic_modal_rate  1.571523e-08  5.971788e-08   \n",
       "10  claude     first_person_rate  9.308415e-05  2.947665e-04   \n",
       "7   claude            hedge_rate  2.384883e-04  6.473253e-04   \n",
       "9   claude    deontic_modal_rate  2.931749e-03  6.962904e-03   \n",
       "12  claude          apology_rate  5.482710e-03  1.157461e-02   \n",
       "5   claude                qmarks  2.140763e-02  4.067449e-02   \n",
       "1   claude               n_words  5.967094e-02  9.447899e-02   \n",
       "6   claude                emarks  5.839774e-02  9.447899e-02   \n",
       "14  claude        agreement_rate  7.010837e-02  1.024661e-01   \n",
       "0   claude               n_chars  1.659252e-01  2.251842e-01   \n",
       "16  claude              pos_rate  3.143647e-01  3.981953e-01   \n",
       "15  claude        deference_rate  4.761118e-01  5.653827e-01   \n",
       "4   claude                   ttr  5.129822e-01  5.733331e-01   \n",
       "11  claude    second_person_rate  7.278819e-01  7.683198e-01   \n",
       "17  claude              neg_rate  8.486965e-01  8.486965e-01   \n",
       "37   gpt4o   flesch_reading_ease  1.357368e-27  2.578998e-26   \n",
       "\n",
       "    significant_q<0.05  \n",
       "2                 True  \n",
       "18                True  \n",
       "13                True  \n",
       "3                 True  \n",
       "8                 True  \n",
       "10                True  \n",
       "7                 True  \n",
       "9                 True  \n",
       "12                True  \n",
       "5                 True  \n",
       "1                False  \n",
       "6                False  \n",
       "14               False  \n",
       "0                False  \n",
       "16               False  \n",
       "15               False  \n",
       "4                False  \n",
       "11               False  \n",
       "17               False  \n",
       "37                True  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics = [c.replace(\"_base\",\"\") for c in feat_df.columns if c.endswith(\"_base\")]\n",
    "results = []\n",
    "\n",
    "def bh_fdr(pvals):\n",
    "    pvals = np.array(pvals, dtype=float)\n",
    "    n = len(pvals)\n",
    "    order = np.argsort(pvals)\n",
    "    ranked = np.empty(n); ranked[order] = np.arange(1, n+1)\n",
    "    qvals = pvals * n / ranked\n",
    "    for i in range(n-2, -1, -1):\n",
    "        qvals[order[i]] = min(qvals[order[i]], qvals[order[i+1]])\n",
    "    return np.minimum(qvals, 1.0)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "def paired_perm_test(a, b, n_perm=20000):\n",
    "    d = np.asarray(b) - np.asarray(a)\n",
    "    d = d[~np.isnan(d)]\n",
    "    obs = abs(d.mean())\n",
    "    if len(d) == 0:\n",
    "        return np.nan\n",
    "    count = 0\n",
    "    for _ in range(n_perm):\n",
    "        flips = rng.choice([-1,1], size=len(d))\n",
    "        val = abs((d*flips).mean())\n",
    "        if val >= obs:\n",
    "            count += 1\n",
    "    return (count + 1) / (n_perm + 1)\n",
    "\n",
    "for model_name, sub in feat_df.groupby(\"model\"):\n",
    "    for m in metrics:\n",
    "        a = sub[f\"{m}_base\"].to_numpy()\n",
    "        b = sub[f\"{m}_cot\"].to_numpy()\n",
    "        if np.all(np.isnan(a)) or np.all(np.isnan(b)):\n",
    "            pval = np.nan\n",
    "        else:\n",
    "            if SCIPY_AVAILABLE:\n",
    "                try:\n",
    "                    _, pval = stats.ttest_rel(a, b, nan_policy=\"omit\")\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        _, pval = stats.wilcoxon(a - b, zero_method='wilcox', alternative='two-sided', correction=False, mode='approx')\n",
    "                    except Exception:\n",
    "                        pval = paired_perm_test(a, b, n_perm=10000)\n",
    "            else:\n",
    "                pval = paired_perm_test(a, b, n_perm=20000)\n",
    "        results.append({\"model\": model_name, \"metric\": m, \"p_value\": pval})\n",
    "\n",
    "stats_df = pd.DataFrame(results)\n",
    "adj_list = []\n",
    "for model_name, sub in stats_df.groupby(\"model\"):\n",
    "    qvals = bh_fdr(sub[\"p_value\"].values)\n",
    "    temp = sub.copy()\n",
    "    temp[\"q_value\"] = qvals\n",
    "    temp[\"significant_q<0.05\"] = temp[\"q_value\"] < 0.05\n",
    "    adj_list.append(temp)\n",
    "stats_df = pd.concat(adj_list, ignore_index=True)\n",
    "\n",
    "stats_df.sort_values([\"model\",\"q_value\"]).head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdb4fc",
   "metadata": {},
   "source": [
    "## Visualizations: Paired Boxplots and Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc3c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
      "/var/folders/2f/b8052dzx5mq4xtzyx0n849x00000gn/T/ipykernel_81329/2005329949.py:7: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def plot_paired_box_and_lines(metric, model_name, save=True):\n",
    "    sub = feat_df[feat_df[\"model\"]==model_name]\n",
    "    base_vals = sub[f\"{metric}_base\"].values\n",
    "    cot_vals  = sub[f\"{metric}_cot\"].values\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,4))\n",
    "    ax.boxplot([base_vals, cot_vals], labels=[\"baseline\", \"cot\"], showfliers=False)\n",
    "    x1, x2 = 1, 2\n",
    "    for a, b in zip(base_vals, cot_vals):\n",
    "        ax.plot([x1, x2], [a, b], alpha=0.2)\n",
    "    ax.set_title(f\"{model_name}: {metric}\")\n",
    "    ax.set_ylabel(metric)\n",
    "    if save:\n",
    "        fig_path = os.path.join(OUT_DIR, f\"{model_name}_{metric}_paired.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(fig_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "        return fig_path\n",
    "    else:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return None\n",
    "\n",
    "SELECT_METRICS = [\"n_words\", \"avg_words_per_sent\", \"ttr\", \"hedge_rate\", \"empathy_rate\", \"deontic_modal_rate\", \"first_person_rate\", \"second_person_rate\", \"flesch_reading_ease\"]\n",
    "plot_files = []\n",
    "for model_name in feat_df[\"model\"].unique():\n",
    "    for m in SELECT_METRICS:\n",
    "        plot_files.append(plot_paired_box_and_lines(m, model_name, save=True))\n",
    "len(plot_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a5f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_wordcloud(texts, title, out_path):\n",
    "    text_combined = \"\\n\".join([t if isinstance(t,str) else \"\" for t in texts])\n",
    "    if WORDCLOUD_AVAILABLE:\n",
    "        wc = WordCloud(width=800, height=400).generate(text_combined)\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        ax.imshow(wc, interpolation='bilinear')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        toks = [w for w in re.findall(r\"[A-Za-z']+\", text_combined.lower()) if len(w) > 2]\n",
    "        from collections import Counter\n",
    "        freq = Counter(toks).most_common(60)\n",
    "        words, counts = zip(*freq) if freq else ([],[])\n",
    "        sizes = np.array(counts) / max(counts) * 40 if counts else np.array([])\n",
    "        xs = np.random.RandomState(0).rand(len(words))\n",
    "        ys = np.random.RandomState(1).rand(len(words))\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        for w, x, y, s in zip(words, xs, ys, sizes):\n",
    "            ax.text(x, y, w, fontsize=max(6, s))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "for model_name, sub in paired.groupby(\"model\"):\n",
    "    base_texts = sub[\"text_base\"].tolist()\n",
    "    cot_texts  = sub[\"text_cot\"].tolist()\n",
    "    p1 = os.path.join(OUT_DIR, f\"{model_name}_baseline_wordcloud.png\")\n",
    "    p2 = os.path.join(OUT_DIR, f\"{model_name}_cot_wordcloud.png\")\n",
    "    generate_wordcloud(base_texts, f\"{model_name} baseline\", p1)\n",
    "    generate_wordcloud(cot_texts, f\"{model_name} CoT\", p2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35851d68",
   "metadata": {},
   "source": [
    "## Representative Excerpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1db7cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "metric",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "delta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "post_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "baseline_excerpt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "cot_excerpt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4e38e7b9-1feb-4f1a-93e9-621c0f647690",
       "rows": [
        [
         "0",
         "gpt4o",
         "n_words",
         "61.0",
         "yy377h",
         "i'm really sorry you're going through this it sounds incredibly tough and your feelings are valid relationships can be complex especially with a history like yours it's important to prioritize your safety and well being as well as your baby's it might be worth having a calm conversation with your husband about boundaries and expectations especially regarding mutual respect therapy ...",
         "it sounds like you're dealing with a very complex and emotionally charged situation and it's understandable that you're feeling overwhelmed it's clear that you care deeply about your relationship and your future as a family but you're also facing some significant challenges it s important to prioritize your safety and well being especially during your pregnancy the incident with the ..."
        ],
        [
         "1",
         "gpt4o",
         "n_words",
         "55.0",
         "zg3d5w",
         "i'm so sorry you're going through this it sounds incredibly overwhelming and unfair you deserve a partner who shares responsibilities and values your well being it s concerning that your boyfriend isn't supporting you or respecting your boundaries his behavior is affecting your mental health and that's not okay consider reaching out to local resources or hotlines for support they ...",
         "it sounds like you're in an incredibly challenging situation and it's understandable that you're feeling overwhelmed and exhausted from what you've shared it seems like your relationship has become one sided with you taking on the majority of responsibilities without the support you deserve it's crucial to recognize that your well being and mental health are important and that you ..."
        ],
        [
         "2",
         "gpt4o",
         "n_words",
         "-38.0",
         "wjgb6z",
         "it's completely okay to not want kids and you're definitely not the asshole for knowing what you want out of life it sounds like you're in a tough spot because you love your husband and don t want to hurt him but this is a fundamental difference that s important to address kids are a huge commitment and having them ...",
         "it's understandable that you're feeling conflicted and pressured right now it's important to remember that your feelings and choices are valid deciding whether or not to have children is a deeply personal decision and it's okay to not want them it sounds like you re feeling a lot of pressure from both your husband and your family which can be ..."
        ],
        [
         "3",
         "gpt4o",
         "n_words",
         "-27.0",
         "urygph",
         "hey there it sounds like you're sharing a pretty popular opinion that many people expressed during and after the trial the public reaction to amber heard s testimony was intense and it s understandable that people have strong feelings about it it's important to remember that in high profile cases like this media portrayal can heavily influence public perception it ...",
         "it sounds like you have strong feelings about amber heard's testimony it's not uncommon for people to have varying opinions on high profile cases especially when emotions are involved it's important to remember that everyone's perspective is shaped by their own experiences and beliefs joking about it might be a way for you to express your thoughts but it's also ..."
        ],
        [
         "4",
         "gpt4o",
         "hedge_rate",
         "5.97333533068684",
         "tjfslw",
         "hey there i'm really sorry to hear about what you and your mom have been going through losing someone is incredibly tough and everyone grieves differently it sounds like your mom is still struggling with her grief and it's understandable you find her behavior around your stepdad's memory a bit unsettling it's important to remember that grief can be a ...",
         "it sounds like you're in a really tough situation and it's understandable to feel frustrated grieving is a deeply personal process and everyone experiences it differently while you've found a way to move forward your mom might still be processing her emotions it's important to recognize that her way of coping though different from yours is valid it seems like ..."
        ],
        [
         "5",
         "gpt4o",
         "hedge_rate",
         "5.423280423280424",
         "zn6dwk",
         "i'm sorry you're in such a tough spot it sounds like you've sacrificed a lot for your family and it s understandable that you re feeling overwhelmed your health and well being are just as important as anyone else's in your family and it seems like you ve reached a point where you need to prioritize that your feelings about ...",
         "you re in a very challenging situation and it s understandable to feel overwhelmed with everything you re managing it seems like you ve been carrying a heavy load for a long time both physically and emotionally your concerns about not wanting more children and prioritizing your health are valid and important it's crucial for both partners to be on ..."
        ],
        [
         "6",
         "gpt4o",
         "hedge_rate",
         "-5.812143227815257",
         "z1f47a",
         "hey there it s totally understandable to feel hesitant about dating someone without a stable job especially when you ve worked hard to achieve financial independence it s important to have standards that reflect your goals and lifestyle being financially stable is a significant aspect of a partnership and it s okay to want a partner who aligns with your ...",
         "it sounds like you have clear standards and expectations for what you want in a partner especially given your background and the lifestyle you ve worked hard to achieve it's understandable to want a partner who is financially stable and can contribute equally to a relationship your feelings about wanting someone who can share in the responsibilities and lifestyle you ..."
        ],
        [
         "7",
         "gpt4o",
         "hedge_rate",
         "-5.744949494949495",
         "zyt4dx",
         "hey there i'm really sorry to hear what you've been going through it sounds like you're in a tough spot and it's totally understandable that your mental health is suffering it's important to prioritize your well being and it sounds like you've been more than supportive of your sister and her kids standing up for yourself isn't easy especially when ...",
         "it truly sounds like you're in a tough spot feeling overextended and pressured by your current situation it's important to prioritize your mental health and well being and setting boundaries with your sister is a necessary step even if it's challenging you are not the villain for needing to focus on yourself in fact being honest with her about your ..."
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>delta</th>\n",
       "      <th>post_id</th>\n",
       "      <th>baseline_excerpt</th>\n",
       "      <th>cot_excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>n_words</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>yy377h</td>\n",
       "      <td>i'm really sorry you're going through this it ...</td>\n",
       "      <td>it sounds like you're dealing with a very comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>n_words</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>zg3d5w</td>\n",
       "      <td>i'm so sorry you're going through this it soun...</td>\n",
       "      <td>it sounds like you're in an incredibly challen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>n_words</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>wjgb6z</td>\n",
       "      <td>it's completely okay to not want kids and you'...</td>\n",
       "      <td>it's understandable that you're feeling confli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>n_words</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>urygph</td>\n",
       "      <td>hey there it sounds like you're sharing a pret...</td>\n",
       "      <td>it sounds like you have strong feelings about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>hedge_rate</td>\n",
       "      <td>5.973335</td>\n",
       "      <td>tjfslw</td>\n",
       "      <td>hey there i'm really sorry to hear about what ...</td>\n",
       "      <td>it sounds like you're in a really tough situat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>hedge_rate</td>\n",
       "      <td>5.423280</td>\n",
       "      <td>zn6dwk</td>\n",
       "      <td>i'm sorry you're in such a tough spot it sound...</td>\n",
       "      <td>you re in a very challenging situation and it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>hedge_rate</td>\n",
       "      <td>-5.812143</td>\n",
       "      <td>z1f47a</td>\n",
       "      <td>hey there it s totally understandable to feel ...</td>\n",
       "      <td>it sounds like you have clear standards and ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4o</td>\n",
       "      <td>hedge_rate</td>\n",
       "      <td>-5.744949</td>\n",
       "      <td>zyt4dx</td>\n",
       "      <td>hey there i'm really sorry to hear what you've...</td>\n",
       "      <td>it truly sounds like you're in a tough spot fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model      metric      delta post_id  \\\n",
       "0  gpt4o     n_words  61.000000  yy377h   \n",
       "1  gpt4o     n_words  55.000000  zg3d5w   \n",
       "2  gpt4o     n_words -38.000000  wjgb6z   \n",
       "3  gpt4o     n_words -27.000000  urygph   \n",
       "4  gpt4o  hedge_rate   5.973335  tjfslw   \n",
       "5  gpt4o  hedge_rate   5.423280  zn6dwk   \n",
       "6  gpt4o  hedge_rate  -5.812143  z1f47a   \n",
       "7  gpt4o  hedge_rate  -5.744949  zyt4dx   \n",
       "\n",
       "                                    baseline_excerpt  \\\n",
       "0  i'm really sorry you're going through this it ...   \n",
       "1  i'm so sorry you're going through this it soun...   \n",
       "2  it's completely okay to not want kids and you'...   \n",
       "3  hey there it sounds like you're sharing a pret...   \n",
       "4  hey there i'm really sorry to hear about what ...   \n",
       "5  i'm sorry you're in such a tough spot it sound...   \n",
       "6  hey there it s totally understandable to feel ...   \n",
       "7  hey there i'm really sorry to hear what you've...   \n",
       "\n",
       "                                         cot_excerpt  \n",
       "0  it sounds like you're dealing with a very comp...  \n",
       "1  it sounds like you're in an incredibly challen...  \n",
       "2  it's understandable that you're feeling confli...  \n",
       "3  it sounds like you have strong feelings about ...  \n",
       "4  it sounds like you're in a really tough situat...  \n",
       "5  you re in a very challenging situation and it ...  \n",
       "6  it sounds like you have clear standards and ex...  \n",
       "7  it truly sounds like you're in a tough spot fe...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"[A-Za-z']+\", (text or \"\").lower())\n",
    "\n",
    "def excerpt(s, n=80):\n",
    "    toks = tokenize(s or \"\")\n",
    "    return \" \".join(toks[:n]) + (\" ...\" if len(toks) > n else \"\")\n",
    "\n",
    "texts_base = {(r.post_id, r.model): r.text_base for _, r in paired.iterrows()}\n",
    "texts_cot  = {(r.post_id, r.model): r.text_cot  for _, r in paired.iterrows()}\n",
    "\n",
    "EXCERPT_ROWS = []\n",
    "for model_name in feat_df[\"model\"].unique():\n",
    "    for metric in [\"n_words\", \"hedge_rate\", \"empathy_rate\", \"deontic_modal_rate\", \"first_person_rate\", \"second_person_rate\"]:\n",
    "        tmp = feat_df[feat_df[\"model\"]==model_name].copy()\n",
    "        tmp[\"delta\"] = tmp[f\"{metric}_cot\"] - tmp[f\"{metric}_base\"]\n",
    "        top_pos = tmp.nlargest(2, \"delta\")\n",
    "        top_neg = tmp.nsmallest(2, \"delta\")\n",
    "        for _, r in pd.concat([top_pos, top_neg]).iterrows():\n",
    "            key = (r[\"post_id\"], model_name)\n",
    "            EXCERPT_ROWS.append({\n",
    "                \"model\": model_name,\n",
    "                \"metric\": metric,\n",
    "                \"delta\": r[\"delta\"],\n",
    "                \"post_id\": r[\"post_id\"],\n",
    "                \"baseline_excerpt\": excerpt(texts_base[key], 60),\n",
    "                \"cot_excerpt\": excerpt(texts_cot[key], 60)\n",
    "            })\n",
    "excerpts_df = pd.DataFrame(EXCERPT_ROWS)\n",
    "excerpts_df.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c95542",
   "metadata": {},
   "source": [
    "## Differential TF–IDF Terms (CoT − Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac34558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_outputs = []\n",
    "if SKLEARN_AVAILABLE:\n",
    "    for model_name, sub in paired.groupby(\"model\"):\n",
    "        docs_base = sub[\"text_base\"].fillna(\"\").tolist()\n",
    "        docs_cot  = sub[\"text_cot\"].fillna(\"\").tolist()\n",
    "        vectorizer = TfidfVectorizer(lowercase=True, token_pattern=r\"[A-Za-z']+\", min_df=2, max_df=0.95)\n",
    "        X = vectorizer.fit_transform(docs_base + docs_cot)\n",
    "        vocab = np.array(vectorizer.get_feature_names_out())\n",
    "        n = len(docs_base)\n",
    "        mean_base = np.asarray(X[:n].mean(axis=0)).ravel()\n",
    "        mean_cot  = np.asarray(X[n:].mean(axis=0)).ravel()\n",
    "        diff = mean_cot - mean_base\n",
    "        top_cot_idx = diff.argsort()[::-1][:30]\n",
    "        top_base_idx = diff.argsort()[:30]\n",
    "        tfidf_outputs.append({\n",
    "            \"model\": model_name,\n",
    "            \"top_terms_cot_minus_base\": list(zip(vocab[top_cot_idx].tolist(), diff[top_cot_idx].round(4).tolist())),\n",
    "            \"top_terms_base_minus_cot\": list(zip(vocab[top_base_idx].tolist(), diff[top_base_idx].round(4).tolist())),\n",
    "        })\n",
    "tfidf_outputs[:2] if tfidf_outputs else \"sklearn not available\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8f6b7",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90813a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feat_df_path = os.path.join(OUT_DIR, \"paired_feature_metrics.csv\")\n",
    "stats_path   = os.path.join(OUT_DIR, \"metric_significance_by_model.csv\")\n",
    "excerpts_path= os.path.join(OUT_DIR, \"excerpts_top_differences.csv\")\n",
    "\n",
    "feat_df.to_csv(feat_df_path, index=False)\n",
    "pd.concat(tfidf_outputs).to_json(os.path.join(OUT_DIR, \"tfidf_differential_terms.json\"), orient=\"records\", indent=2) if tfidf_outputs else None\n",
    "\n",
    "stats_df.to_csv(stats_path, index=False)\n",
    "excerpts_df.to_csv(excerpts_path, index=False)\n",
    "\n",
    "feat_df_path, stats_path, excerpts_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-312-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
